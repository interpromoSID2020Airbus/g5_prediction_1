{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1><b>Groupe 5 - Prediction</b>\n",
    "> Result Notebook\n",
    "\n",
    "\n",
    "<span class=\"tocSkip\"></span>\n",
    "> *Authors : All*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Genereal-explaination\" data-toc-modified-id=\"Genereal-explaination-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Genereal explaination</a></span></li><li><span><a href=\"#Notebook's-aim\" data-toc-modified-id=\"Notebook's-aim-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Notebook's aim</a></span></li><li><span><a href=\"#Highlights\" data-toc-modified-id=\"Highlights-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Highlights</a></span></li></ul></li><li><span><a href=\"#Environment\" data-toc-modified-id=\"Environment-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Environment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Libraries-:\" data-toc-modified-id=\"Libraries-:-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Libraries :</a></span></li><li><span><a href=\"#Data-loading-:\" data-toc-modified-id=\"Data-loading-:-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Data loading :</a></span></li><li><span><a href=\"#Functions-:\" data-toc-modified-id=\"Functions-:-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Functions :</a></span></li></ul></li><li><span><a href=\"#Textual-analysis-approach\" data-toc-modified-id=\"Textual-analysis-approach-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Textual analysis approach</a></span><ul class=\"toc-item\"><li><span><a href=\"#V0\" data-toc-modified-id=\"V0-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>V0</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading\" data-toc-modified-id=\"Loading-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Loading</a></span></li><li><span><a href=\"#Models-creation\" data-toc-modified-id=\"Models-creation-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Models creation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Seat-Comfort\" data-toc-modified-id=\"Seat-Comfort-3.1.2.1\"><span class=\"toc-item-num\">3.1.2.1&nbsp;&nbsp;</span>Seat Comfort</a></span></li><li><span><a href=\"#Food-&amp;-Beverages\" data-toc-modified-id=\"Food-&amp;-Beverages-3.1.2.2\"><span class=\"toc-item-num\">3.1.2.2&nbsp;&nbsp;</span>Food &amp; Beverages</a></span></li><li><span><a href=\"#Cabin-staff-service\" data-toc-modified-id=\"Cabin-staff-service-3.1.2.3\"><span class=\"toc-item-num\">3.1.2.3&nbsp;&nbsp;</span>Cabin staff service</a></span></li><li><span><a href=\"#Inflight-entertainment\" data-toc-modified-id=\"Inflight-entertainment-3.1.2.4\"><span class=\"toc-item-num\">3.1.2.4&nbsp;&nbsp;</span>Inflight entertainment</a></span></li></ul></li><li><span><a href=\"#Models-evaluation\" data-toc-modified-id=\"Models-evaluation-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Models evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Measures\" data-toc-modified-id=\"Measures-3.1.3.1\"><span class=\"toc-item-num\">3.1.3.1&nbsp;&nbsp;</span>Measures<a name=\"bookmark\"></a></a></span></li><li><span><a href=\"#Comparison\" data-toc-modified-id=\"Comparison-3.1.3.2\"><span class=\"toc-item-num\">3.1.3.2&nbsp;&nbsp;</span>Comparison</a></span></li></ul></li><li><span><a href=\"#Interpretation\" data-toc-modified-id=\"Interpretation-3.1.4\"><span class=\"toc-item-num\">3.1.4&nbsp;&nbsp;</span>Interpretation</a></span></li></ul></li><li><span><a href=\"#V1\" data-toc-modified-id=\"V1-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>V1</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading\" data-toc-modified-id=\"Loading-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Loading</a></span></li><li><span><a href=\"#Models-creation\" data-toc-modified-id=\"Models-creation-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Models creation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Seat-Comfort\" data-toc-modified-id=\"Seat-Comfort-3.2.2.1\"><span class=\"toc-item-num\">3.2.2.1&nbsp;&nbsp;</span>Seat Comfort</a></span></li><li><span><a href=\"#Food-&amp;-Beverages\" data-toc-modified-id=\"Food-&amp;-Beverages-3.2.2.2\"><span class=\"toc-item-num\">3.2.2.2&nbsp;&nbsp;</span>Food &amp; Beverages</a></span></li><li><span><a href=\"#Cabin-staff-service\" data-toc-modified-id=\"Cabin-staff-service-3.2.2.3\"><span class=\"toc-item-num\">3.2.2.3&nbsp;&nbsp;</span>Cabin staff service</a></span></li><li><span><a href=\"#Inflight-entertainment\" data-toc-modified-id=\"Inflight-entertainment-3.2.2.4\"><span class=\"toc-item-num\">3.2.2.4&nbsp;&nbsp;</span>Inflight entertainment</a></span></li></ul></li><li><span><a href=\"#Models-evaluation\" data-toc-modified-id=\"Models-evaluation-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Models evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Measures\" data-toc-modified-id=\"Measures-3.2.3.1\"><span class=\"toc-item-num\">3.2.3.1&nbsp;&nbsp;</span>Measures</a></span></li><li><span><a href=\"#Comparison\" data-toc-modified-id=\"Comparison-3.2.3.2\"><span class=\"toc-item-num\">3.2.3.2&nbsp;&nbsp;</span>Comparison</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Metadata-analysis-approach\" data-toc-modified-id=\"Metadata-analysis-approach-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Metadata analysis approach</a></span><ul class=\"toc-item\"><li><span><a href=\"#V0-:\" data-toc-modified-id=\"V0-:-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>V0 :</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading\" data-toc-modified-id=\"Loading-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Loading</a></span></li><li><span><a href=\"#Models-creation\" data-toc-modified-id=\"Models-creation-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Models creation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Seat-Comfort\" data-toc-modified-id=\"Seat-Comfort-4.1.2.1\"><span class=\"toc-item-num\">4.1.2.1&nbsp;&nbsp;</span>Seat Comfort</a></span></li><li><span><a href=\"#Food-&amp;-Beverages\" data-toc-modified-id=\"Food-&amp;-Beverages-4.1.2.2\"><span class=\"toc-item-num\">4.1.2.2&nbsp;&nbsp;</span>Food &amp; Beverages</a></span></li><li><span><a href=\"#Cabin-staff-service\" data-toc-modified-id=\"Cabin-staff-service-4.1.2.3\"><span class=\"toc-item-num\">4.1.2.3&nbsp;&nbsp;</span>Cabin staff service</a></span></li><li><span><a href=\"#Inflight-entertainment\" data-toc-modified-id=\"Inflight-entertainment-4.1.2.4\"><span class=\"toc-item-num\">4.1.2.4&nbsp;&nbsp;</span>Inflight entertainment</a></span></li></ul></li><li><span><a href=\"#Models-evaluation\" data-toc-modified-id=\"Models-evaluation-4.1.3\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>Models evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Measures\" data-toc-modified-id=\"Measures-4.1.3.1\"><span class=\"toc-item-num\">4.1.3.1&nbsp;&nbsp;</span>Measures</a></span></li><li><span><a href=\"#Comparison\" data-toc-modified-id=\"Comparison-4.1.3.2\"><span class=\"toc-item-num\">4.1.3.2&nbsp;&nbsp;</span>Comparison</a></span></li></ul></li></ul></li><li><span><a href=\"#V1-:\" data-toc-modified-id=\"V1-:-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>V1 :</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading\" data-toc-modified-id=\"Loading-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Loading</a></span></li><li><span><a href=\"#Models-creation\" data-toc-modified-id=\"Models-creation-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Models creation</a></span></li><li><span><a href=\"#Models-evaluation\" data-toc-modified-id=\"Models-evaluation-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span>Models evaluation</a></span></li></ul></li><li><span><a href=\"#V2-:\" data-toc-modified-id=\"V2-:-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>V2 :</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading\" data-toc-modified-id=\"Loading-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Loading</a></span></li><li><span><a href=\"#Models-creation\" data-toc-modified-id=\"Models-creation-4.3.2\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>Models creation</a></span></li><li><span><a href=\"#Models-evaluation\" data-toc-modified-id=\"Models-evaluation-4.3.3\"><span class=\"toc-item-num\">4.3.3&nbsp;&nbsp;</span>Models evaluation</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genereal explaination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of our group was to predict what could be considered as features of comfort in cabin during flights. In order to answer this question, we decided to work on 2 approaches : \n",
    "- The first one is the textual analysis approach. It consists in analysing the commentaries as a group of word, by cleaning and adapting data, and then building supervised machine learning models that will be examined in order to find the words that explains the most a given label.\n",
    "- The second one is the analysis of metadata. We have been given some files that have been scrapped from the web before this project. Thanks to these files, we have access to data like airline name, type of aircraft or width of a seat... linked to a customer and then to a label. The aim of this approach is the same as the previous one : get the features that explain the most a given label.\n",
    "\n",
    "For both approaches, the labels that are predicted are : \n",
    "- Seat Comfort : grade given between 0 and 5 about general comfort of seats\n",
    "- Food & Beverages : grade given between 0 and 5 about food and beverages served onboard\n",
    "- Cabin Staff Service : grade given between 0 and 5 about cabin crew\n",
    "- Inflight Entertainment : grade given between 0 and 5 on about entertainment during flight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook's aim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook's aim is to present results of the two main analysis approach we have made.\n",
    "\n",
    "It is separeted in 3 main parts : \n",
    "- The first one is the environnement setting, with imports of libraries and functions, and data loading.\n",
    "- The second one gathers all versions of the textual analysis approach. Things that can be found in this part are models creation, evaluation and conclusions.\n",
    "- The last one is the equivalent but for the metadata analysis approach.\n",
    "\n",
    "Some explaining cells will be used sometimes in order to interprate, or conclude about the previous code cell.\n",
    "\n",
    "Commentaries in Python parts (starting with #) are here to understand what is done and how.\n",
    "\n",
    "Charts of evolution are also avaliable when relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our project is based on two parallel works.\n",
    "\n",
    "Important points of this notebook are :\n",
    "- The best approach is metadata analysis\n",
    "- On textual analysis \n",
    "   - We worked on customer feedbacks\n",
    "   - best version uses the TF-IDF as on a small list of words and new created features\n",
    "   - We tried several models and the best one is for logistic regression for all labels\n",
    "- On metadata analysis\n",
    "    - We filled our dataset with statistical and logical approaches\n",
    "    - We got the best score of prediction for random forest and LGBM\n",
    "    - Unfortunately, our feature creationswere not successful. Our scores were not as good as previous version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T16:00:10.127967Z",
     "start_time": "2020-01-17T16:00:08.697428Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import json\n",
    "import scipy.stats as stats\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "from warnings import filterwarnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T16:00:10.612804Z",
     "start_time": "2020-01-17T16:00:10.600790Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ignoring warnings\n",
    "pd.options.mode.chained_assignment = None\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run this Notebook, some files are required. Then, the path needs to be changed and to lead to the folder where files are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T16:00:33.731069Z",
     "start_time": "2020-01-17T16:00:12.977856Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"Files_to_load/\"\n",
    "\n",
    "all_data = pd.read_excel(path + \"ALL_DATA.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T16:00:38.986876Z",
     "start_time": "2020-01-17T16:00:34.495864Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing functions from g5_notebook_functions Notebook\n",
    "from ipynb.fs.full.g5_notebook_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Textual analysis approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this version, we decided to deal with only 3 labels, because the last one (Inflight Entertainment) was more than half empty. As this is the first version, we only tried to build a concrete pipeline containing pre-processing, models building and evaluation, no matter what the results was."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to run this part, use the 'small' CSVs given (only 1000 rows). If you don't want to alter the results then <span style= 'background:red'> DONT RUN THIS VERSION </span> (Very long execution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T09:27:45.436519Z",
     "start_time": "2020-01-15T09:23:35.816796Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading DataFrames that already have been processed and divided by label.\n",
    "data_seat = pd.read_csv(path + 'g5_seat_V0.csv')\n",
    "data_food = pd.read_csv(path + 'g5_food_V0.csv')\n",
    "data_staff = pd.read_csv(path + 'g5_staff_V0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use the <span style= 'background:orange'> model_computing</span>  function, refer to th function notebook to see further information.\n",
    "\n",
    "For each of the 3 labels, we compare results of K Nearest Neighboors,  logistic regression and random forest with default parameters. Indeed, a parameter optimisation will be done later, only in other versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seat Comfort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T09:27:52.931829Z",
     "start_time": "2020-01-15T09:27:45.438518Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_seat = data_seat.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T09:28:03.987009Z",
     "start_time": "2020-01-15T09:27:52.935828Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = data_seat.drop([\"Seat_Comfort\"], axis=1), data_seat[\"Seat_Comfort\"]\n",
    "\n",
    "# Dividing data into train and test set (70% - 30%)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T10:14:35.826895Z",
     "start_time": "2020-01-15T09:28:03.989990Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn_seat = model_computing(X, y, 'knn', 'seat_comfort', [5],\n",
    "                           X_train, Y_train, X_test,\n",
    "                           Y_test)\n",
    "print('KNN done')\n",
    "\n",
    "# Logistic regression\n",
    "lr_seat = model_computing(X, y, 'logistic_regression', 'seat_comfort', [],\n",
    "                          X_train, Y_train, X_test, Y_test)\n",
    "print('Logistic regression done')\n",
    "\n",
    "# Random Forest\n",
    "rf_seat = model_computing(X, y ,'random_forest', 'seat_comfort', [5, 42, 100],\n",
    "                          X_train, Y_train, X_test, Y_test)\n",
    "print('Random Forest done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Food & Beverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T10:14:43.619993Z",
     "start_time": "2020-01-15T10:14:35.980849Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_food = data_food.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T10:14:49.578979Z",
     "start_time": "2020-01-15T10:14:43.621993Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = data_food.drop([\"Food_And_Beverages\"], axis=1), data_food[\"Food_And_Beverages\"]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T10:54:33.559856Z",
     "start_time": "2020-01-15T10:14:49.581978Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn_food = model_computing(X, y, 'knn', 'food_and_beverages', [5],\n",
    "                           X_train, Y_train, X_test, Y_test)\n",
    "print('KNN done')\n",
    "\n",
    "# Logistic regression\n",
    "lr_food = model_computing(X, y, 'logistic_regression', 'food_and_beverages', [],\n",
    "                          X_train, Y_train, X_test, Y_test)\n",
    "print('Logistic regression done')\n",
    "\n",
    "# Random Forest\n",
    "rf_food = model_computing(X, y, 'random_forest', 'food_and_beverages', [5, 42, 100],\n",
    "                          X_train, Y_train, X_test, Y_test)\n",
    "print('Random Forest done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cabin staff service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T10:54:40.954930Z",
     "start_time": "2020-01-15T10:54:33.566837Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_staff = data_staff.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T10:54:47.067254Z",
     "start_time": "2020-01-15T10:54:40.956916Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = data_staff.drop([\"Cabin_Staff_Service\"],\n",
    "                       axis=1), data_staff[\"Cabin_Staff_Service\"]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T11:41:32.096617Z",
     "start_time": "2020-01-15T10:54:47.069210Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn_staff = model_computing(X, y, 'knn', 'cabin_staff_service', [5],\n",
    "                            X_train, Y_train, X_test, Y_test)\n",
    "print('KNN done')\n",
    "\n",
    "# Logistic regression\n",
    "lr_staff = model_computing(X, y, 'logistic_regression', 'cabin_staff_service', [],\n",
    "                           X_train, Y_train, X_test, Y_test)\n",
    "print('Logistic regression done')\n",
    "\n",
    "# Random Forest\n",
    "rf_staff = model_computing(X, y, 'random_forest', 'cabin_staff_service', [5, 42, 100],\n",
    "                           X_train, Y_train, X_test, Y_test)\n",
    "print('Random Forest done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inflight entertainment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not present in this version because to many Nans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measures<a name='bookmark'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We decided to use 2 main metrics in order to evaluate our models : \n",
    "- Accuracy score on a given dataset (percentage of correct prediction)\n",
    "- Mean error on the prediction on a given dataset\n",
    "- Average accuracy scores computed by cross validation\n",
    "- Variance of accuracy scores computed by cross validation\n",
    "\n",
    "Cross validation is made to avoid over fitting. By computing the scores on different datasets, we can observe the variance in order to see how dispersed the results are. A low variance means that no matter the dataset we still havethe same rate of accuracy, wich means no over-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T11:41:32.212568Z",
     "start_time": "2020-01-15T11:41:32.102613Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_knn_accuracy = [knn_seat[0], knn_food[0], knn_staff[0]]\n",
    "list_lr_accuracy = [lr_seat[0], lr_food[0], lr_staff[0]]\n",
    "list_rf_accuracy = [rf_seat[0], rf_food[0], rf_staff[0]]\n",
    "\n",
    "list_knn_mean_error = [knn_seat[1], knn_food[1], knn_staff[1]]\n",
    "list_lr_mean_error = [lr_seat[1], lr_food[1], lr_staff[1]]\n",
    "list_rf_mean_error = [rf_seat[1], rf_food[1], rf_staff[1]]\n",
    "\n",
    "list_knn_cv_mean = [knn_seat[2], knn_food[2], knn_staff[2]]\n",
    "list_lr_cv_mean = [lr_seat[2], lr_food[2], lr_staff[2]]\n",
    "list_rf_cv_mean = [rf_seat[2], rf_food[2], rf_staff[2]]\n",
    "\n",
    "list_knn_cv_var = [knn_seat[3], knn_food[3], knn_staff[3]]\n",
    "list_lr_cv_var = [lr_seat[3], lr_food[3], lr_staff[3]]\n",
    "list_rf_cv_var = [rf_seat[3], rf_food[3], rf_staff[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T11:41:33.823435Z",
     "start_time": "2020-01-15T11:41:32.214548Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_bars_model(['KNN', 'Logistic regression', 'Random forest'], \n",
    "                 [list_knn_accuracy, list_lr_accuracy, list_rf_accuracy],\n",
    "                ['Seat', 'Food', 'Staff'],\n",
    "                'Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can say that accuracy seems quite low, and that KNN model is the best not matter the label. KNN is followed by logistic regression and then random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T11:41:33.964361Z",
     "start_time": "2020-01-15T11:41:33.826422Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_bars_model(['KNN', 'Logistic regression', 'Random forest'], \n",
    "                 [list_knn_mean_error, list_lr_mean_error, list_rf_mean_error],\n",
    "                ['Seat', 'Food', 'Staff'],\n",
    "                'RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average error is also quite high (we want it to be as low as possible). The best model for this measure seems to be Random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T11:41:34.179306Z",
     "start_time": "2020-01-15T11:41:33.966343Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_bars_model(['KNN', 'Logistic regression', 'Random forest'], \n",
    "                 [list_knn_cv_mean, list_lr_cv_mean, list_rf_cv_mean],\n",
    "                ['Seat', 'Food', 'Staff'],\n",
    "                'Mean cross validation score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is quite interesting with this chart is that we can observe the stability of a given model. For example, we said just before that KNN was the best model for a given dataset. However, this is no longer true when we try with several models : it shows us that KNN is not an enought robust for our case.\n",
    "\n",
    "Here, we can see that it depends also on the label. Logistic regression seems to fit better on the food & beverages label, but random forest fits better on seat comfort label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T11:41:34.421557Z",
     "start_time": "2020-01-15T11:41:34.181291Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_bars_model(['KNN', 'Logistic regression', 'Random forest'], \n",
    "                 [list_knn_cv_var, list_lr_cv_var, list_rf_cv_var],\n",
    "                ['Seat', 'Food', 'Staff'],\n",
    "                'Variance in cross validation scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our models, even in this first version, look like they don't over fit. Indeed, variance is quite low even if it is higher for the Cabin staff label in particular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is not our best models, these will not be interprated. Indeed, what we considered the most appropriated is interprating only those having a correct accuracy score, wich is not the case for this version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:10:04.411282Z",
     "start_time": "2020-01-17T13:10:02.290622Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading DataFrames that already have been processed and divided by label.\n",
    "data_seat_v1 = pd.read_csv(path + 'g5_seat_V1.csv')\n",
    "data_food_v1 = pd.read_csv(path + 'g5_food_V1.csv')\n",
    "data_staff_v1 = pd.read_csv(path + 'g5_staff_V1.csv')\n",
    "data_inflight_v1 = pd.read_csv(path + 'g5_inflight_V1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seat Comfort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:10:29.922749Z",
     "start_time": "2020-01-17T13:10:29.827495Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = data_seat_v1.drop([\"Seat_Comfort\"], axis=1), data_seat_v1[\"Seat_Comfort\"]\n",
    "\n",
    "# Dividing data into train and test set (70% - 30%)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:13:50.640456Z",
     "start_time": "2020-01-17T13:10:30.615292Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn_seat = model_computing(X, y, 'knn', 'seat_comfort', [5],\n",
    "                           X_train, Y_train, X_test,\n",
    "                           Y_test)\n",
    "print('KNN done')\n",
    "\n",
    "# Logistic regression\n",
    "lr_seat = model_computing(X, y, 'logistic_regression', 'seat_comfort', [],\n",
    "                          X_train, Y_train, X_test, Y_test)\n",
    "print('Logistic regression done')\n",
    "\n",
    "# Random Forest\n",
    "rf_seat = model_computing(X, y ,'random_forest', 'seat_comfort', [5, 42, 100],\n",
    "                          X_train, Y_train, X_test, Y_test)\n",
    "print('Random Forest done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Food & Beverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:14:21.565891Z",
     "start_time": "2020-01-17T13:14:21.491695Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = data_food_v1.drop([\"Food_And_Beverages\"], axis=1), data_food_v1[\"Food_And_Beverages\"]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:17:12.337193Z",
     "start_time": "2020-01-17T13:14:25.841346Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn_food = model_computing(X, y, 'knn', 'food_and_beverages', [5],\n",
    "                           X_train, Y_train, X_test, Y_test)\n",
    "print('KNN done')\n",
    "\n",
    "# Logistic regression\n",
    "lr_food = model_computing(X, y, 'logistic_regression', 'food_and_beverages', [],\n",
    "                          X_train, Y_train, X_test, Y_test)\n",
    "print('Logistic regression done')\n",
    "\n",
    "# Random Forest\n",
    "rf_food = model_computing(X, y, 'random_forest', 'food_and_beverages', [5, 42, 100],\n",
    "                          X_train, Y_train, X_test, Y_test)\n",
    "print('Random Forest done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cabin staff service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:17:19.856614Z",
     "start_time": "2020-01-17T13:17:19.762363Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = data_staff_v1.drop([\"Cabin_Staff_Service\"],\n",
    "                       axis=1), data_staff_v1[\"Cabin_Staff_Service\"]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:20:36.612112Z",
     "start_time": "2020-01-17T13:17:21.008955Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn_staff = model_computing(X, y, 'knn', 'cabin_staff_service', [5],\n",
    "                            X_train, Y_train, X_test, Y_test)\n",
    "print('KNN done')\n",
    "\n",
    "# Logistic regression\n",
    "lr_staff = model_computing(X, y, 'logistic_regression', 'cabin_staff_service', [],\n",
    "                           X_train, Y_train, X_test, Y_test)\n",
    "print('Logistic regression done')\n",
    "\n",
    "# Random Forest\n",
    "rf_staff = model_computing(X, y, 'random_forest', 'cabin_staff_service', [5, 42, 100],\n",
    "                           X_train, Y_train, X_test, Y_test)\n",
    "print('Random Forest done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inflight entertainment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:22:56.567029Z",
     "start_time": "2020-01-17T13:22:56.500855Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = data_inflight_v1.drop([\"Inflight_Entertainment\"],\n",
    "                       axis=1), data_inflight_v1[\"Inflight_Entertainment\"]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:25:19.331982Z",
     "start_time": "2020-01-17T13:22:57.343982Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn_entertainment = model_computing(X, y, 'knn', 'inflight_entertainment', [5],\n",
    "                            X_train, Y_train, X_test, Y_test)\n",
    "print('KNN done')\n",
    "\n",
    "# Logistic regression\n",
    "lr_entertainment = model_computing(X, y, 'logistic_regression', 'inflight_entertainment', [],\n",
    "                           X_train, Y_train, X_test, Y_test)\n",
    "print('Logistic regression done')\n",
    "\n",
    "# Random Forest\n",
    "rf_entertainment = model_computing(X, y, 'random_forest', 'inflight_entertainment', [5, 42, 100],\n",
    "                           X_train, Y_train, X_test, Y_test)\n",
    "print('Random Forest done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measures used for this version are the same than in the V0 of textual analysis approach. Voir <a href=#bookmark>3.1.3.1 Measures</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:26:11.815831Z",
     "start_time": "2020-01-17T13:26:11.785777Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_knn_accuracy = [knn_seat[0], knn_food[0], knn_staff[0], knn_entertainment[0]]\n",
    "list_lr_accuracy = [lr_seat[0], lr_food[0], lr_staff[0], lr_entertainment[0]]\n",
    "list_rf_accuracy = [rf_seat[0], rf_food[0], rf_staff[0], rf_entertainment[0]]\n",
    "\n",
    "list_knn_mean_error = [knn_seat[1], knn_food[1], knn_staff[1], knn_entertainment[1]]\n",
    "list_lr_mean_error = [lr_seat[1], lr_food[1], lr_staff[1], lr_entertainment[1]]\n",
    "list_rf_mean_error = [rf_seat[1], rf_food[1], rf_staff[1], rf_entertainment[1]]\n",
    "\n",
    "list_knn_cv_mean = [knn_seat[2], knn_food[2], knn_staff[2], knn_entertainment[2]]\n",
    "list_lr_cv_mean = [lr_seat[2], lr_food[2], lr_staff[2], lr_entertainment[2]]\n",
    "list_rf_cv_mean = [rf_seat[2], rf_food[2], rf_staff[2], rf_entertainment[2]]\n",
    "\n",
    "list_knn_cv_var = [knn_seat[3], knn_food[3], knn_staff[3], knn_entertainment[3]]\n",
    "list_lr_cv_var = [lr_seat[3], lr_food[3], lr_staff[3], lr_entertainment[3]]\n",
    "list_rf_cv_var = [rf_seat[3], rf_food[3], rf_staff[3], rf_entertainment[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:26:13.165112Z",
     "start_time": "2020-01-17T13:26:12.888796Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_bars_model(['KNN', 'Logistic regression', 'Random forest'], \n",
    "                 [list_knn_accuracy, list_lr_accuracy, list_rf_accuracy],\n",
    "                ['Seat', 'Food', 'Staff', 'Entertainment'],\n",
    "                'Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chart can be interprated this way : our results for a given Dataset and for 3 different models are close, but Logistic regression seems to be the best model for every label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:26:15.320332Z",
     "start_time": "2020-01-17T13:26:15.107771Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_bars_model(['KNN', 'Logistic regression', 'Random forest'], \n",
    "                 [list_knn_mean_error, list_lr_mean_error, list_rf_mean_error],\n",
    "                ['Seat', 'Food', 'Staff', 'Entertainment'],\n",
    "                'RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this measure (RMSE), things are different : Random forest model is has the best average error of prediction. Having the cross validation scores will help us find what model is the most robust no matter wath starting dataset we give it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:26:18.482978Z",
     "start_time": "2020-01-17T13:26:18.268411Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_bars_model(['KNN', 'Logistic regression', 'Random forest'], \n",
    "                 [list_knn_cv_mean, list_lr_cv_mean, list_rf_cv_mean],\n",
    "                ['Seat', 'Food', 'Staff', 'Entertainment'],\n",
    "                'Mean cross validation score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For accuracy score, even with different starting data sets, logistical regression is still the most adapted model for our 4 labels. Let's now see if we don't overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:26:20.228802Z",
     "start_time": "2020-01-17T13:26:20.011229Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_bars_model(['KNN', 'Logistic regression', 'Random forest'], \n",
    "                 [list_knn_cv_var, list_lr_cv_var, list_rf_cv_var],\n",
    "                ['Seat', 'Food', 'Staff', 'Entertainment'],\n",
    "                'Variance in cross validation scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if those results are really low for all of our models, we can see that random forest has the highest variance, especially for entertainment label. This means that as the starting dataset changes, the accuracy score changes too (here the rate is low enought to consider it is just a normal variation).\n",
    "\n",
    "Logistic regression is the best model for this version, according to thoses measures (average accuracy score of 0.67, average RMSE of 0.85)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is the last version of our textual analysis, the models built here will be the ones interprated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata analysis approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V0 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T10:35:01.028653Z",
     "start_time": "2020-01-16T10:35:00.968574Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_MD_V0 = pd.read_csv(path + 'all_data_MD_V0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use the <span style= 'background:orange'> model_computing</span>  function, refer to th function notebook to see further information.\n",
    "\n",
    "For each of the 3 labels, we compare results of K Nearest Neighboors,  logistic regression and random forest with default parameters. Indeed, a parameter optimisation will be done later, only in other versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T10:35:36.682672Z",
     "start_time": "2020-01-16T10:35:36.618588Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['Seat_Comfort', 'Food_And_Beverages', 'Cabin_Staff_Service', 'Inflight_Entertainment']\n",
    "y = all_data_MD_V0[labels]\n",
    "X = all_data_MD_V0.drop(labels, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seat Comfort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T10:35:37.830411Z",
     "start_time": "2020-01-16T10:35:37.734289Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dividing data into train and test set (70% - 30%)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, y['Seat_Comfort'], test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T10:52:12.514604Z",
     "start_time": "2020-01-16T10:35:39.398128Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_seat = model_computing(X, y['Seat_Comfort'], 'knn', 'seat_comfort', [5],\n",
    "                           X_train, Y_train, X_test,\n",
    "                           Y_test)\n",
    "print('KNN done')\n",
    "\n",
    "# Logistic regression\n",
    "lr_seat = model_computing(X, y['Seat_Comfort'], 'logistic_regression', 'seat_comfort', [],\n",
    "                          X_train, Y_train, X_test, Y_test)\n",
    "print('Logistic regression done')\n",
    "\n",
    "# Random Forest\n",
    "rf_seat = model_computing(X, y['Seat_Comfort'], 'random_forest', 'seat_comfort', [5, 42, 100],\n",
    "                          X_train, Y_train, X_test, Y_test)\n",
    "print('Random Forest done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Food & Beverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T12:17:21.218025Z",
     "start_time": "2020-01-16T12:17:21.129911Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test=train_test_split(\n",
    "    X, y['Food_And_Beverages'], test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T12:34:12.143449Z",
     "start_time": "2020-01-16T12:17:23.554190Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn_food = model_computing(X, y['Food_And_Beverages'], 'knn', 'food_and_beverages', [5],\n",
    "                           X_train, Y_train, X_test, Y_test)\n",
    "print('KNN done')\n",
    "\n",
    "# Logistic regression\n",
    "lr_food = model_computing(X, y['Food_And_Beverages'], 'logistic_regression', 'food_and_beverages', [],\n",
    "                          X_train, Y_train, X_test, Y_test)\n",
    "print('Logistic regression done')\n",
    "\n",
    "# Random Forest\n",
    "rf_food = model_computing(X, y['Food_And_Beverages'], 'random_forest', 'food_and_beverages', [5, 42, 100],\n",
    "                          X_train, Y_train, X_test, Y_test)\n",
    "print('Random Forest done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cabin staff service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T12:34:12.988595Z",
     "start_time": "2020-01-16T12:34:12.900480Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, y['Cabin_Staff_Service'], test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T12:50:08.039176Z",
     "start_time": "2020-01-16T12:34:13.733562Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn_staff = model_computing(X, y['Cabin_Staff_Service'], 'knn', 'cabin_staff_service', [5],\n",
    "                            X_train, Y_train, X_test, Y_test)\n",
    "print('KNN done')\n",
    "\n",
    "# Logistic regression\n",
    "lr_staff = model_computing(X, y['Cabin_Staff_Service'], 'logistic_regression', 'cabin_staff_service', [],\n",
    "                           X_train, Y_train, X_test, Y_test)\n",
    "print('Logistic regression done')\n",
    "\n",
    "# Random Forest\n",
    "rf_staff = model_computing(X, y['Cabin_Staff_Service'], 'random_forest', 'cabin_staff_service', [5, 42, 100],\n",
    "                           X_train, Y_train, X_test, Y_test)\n",
    "print('Random Forest done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inflight entertainment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T12:50:08.845463Z",
     "start_time": "2020-01-16T12:50:08.758203Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, y['Inflight_Entertainment'], test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T13:06:29.817442Z",
     "start_time": "2020-01-16T12:50:09.551799Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn_entertainment = model_computing(X, y['Inflight_Entertainment'], 'knn', 'inflight_entertainment', [5],\n",
    "                            X_train, Y_train, X_test, Y_test)\n",
    "print('KNN done')\n",
    "\n",
    "# Logistic regression\n",
    "lr_entertainment = model_computing(X, y['Inflight_Entertainment'], 'logistic_regression', 'inflight_entertainment', [],\n",
    "                           X_train, Y_train, X_test, Y_test)\n",
    "print('Logistic regression done')\n",
    "\n",
    "# Random Forest\n",
    "rf_entertainment = model_computing(X, y['Inflight_Entertainment'], 'random_forest', 'inflight_entertainment', [5, 42, 100],\n",
    "                           X_train, Y_train, X_test, Y_test)\n",
    "print('Random Forest done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measures used for this version are the same than in the V0 of textual analysis approach. Voir <a href=#bookmark>3.1.3.1 Measures</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T13:09:38.450926Z",
     "start_time": "2020-01-16T13:09:38.409811Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_knn_accuracy = [knn_seat[0], knn_food[0], knn_staff[0], knn_entertainment[0]]\n",
    "list_lr_accuracy = [lr_seat[0], lr_food[0], lr_staff[0], lr_entertainment[0]]\n",
    "list_rf_accuracy = [rf_seat[0], rf_food[0], rf_staff[0], rf_entertainment[0]]\n",
    "\n",
    "list_knn_mean_error = [knn_seat[1], knn_food[1], knn_staff[1], knn_entertainment[1]]\n",
    "list_lr_mean_error = [lr_seat[1], lr_food[1], lr_staff[1], lr_entertainment[1]]\n",
    "list_rf_mean_error = [rf_seat[1], rf_food[1], rf_staff[1], rf_entertainment[1]]\n",
    "\n",
    "list_knn_cv_mean = [knn_seat[2], knn_food[2], knn_staff[2], knn_entertainment[2]]\n",
    "list_lr_cv_mean = [lr_seat[2], lr_food[2], lr_staff[2], lr_entertainment[2]]\n",
    "list_rf_cv_mean = [rf_seat[2], rf_food[2], rf_staff[2], rf_entertainment[2]]\n",
    "\n",
    "list_knn_cv_var = [knn_seat[3], knn_food[3], knn_staff[3], knn_entertainment[3]]\n",
    "list_lr_cv_var = [lr_seat[3], lr_food[3], lr_staff[3], lr_entertainment[3]]\n",
    "list_rf_cv_var = [rf_seat[3], rf_food[3], rf_staff[3], rf_entertainment[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T13:09:39.880470Z",
     "start_time": "2020-01-16T13:09:39.521769Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_bars_model(['KNN', 'Logistic regression', 'Random forest'], \n",
    "                 [list_knn_accuracy, list_lr_accuracy, list_rf_accuracy],\n",
    "                ['Seat', 'Food', 'Staff', 'Entertainment'],\n",
    "                'Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chart can be interprated this way : our results for a given Dataset anf for 3 different models are close, but Logistic regression seems to be the best model for every label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T13:09:41.121434Z",
     "start_time": "2020-01-16T13:09:40.881798Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_bars_model(['KNN', 'Logistic regression', 'Random forest'], \n",
    "                 [list_knn_mean_error, list_lr_mean_error, list_rf_mean_error],\n",
    "                ['Seat', 'Food', 'Staff', 'Entertainment'],\n",
    "                'RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this measure (RMSE), things are different : Random forest model is has the best average error of prediction. Having the cross validation scores will help us find what model is the most robust no matter wath starting dataset we give it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T13:09:42.385793Z",
     "start_time": "2020-01-16T13:09:42.161195Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_bars_model(['KNN', 'Logistic regression', 'Random forest'], \n",
    "                 [list_knn_cv_mean, list_lr_cv_mean, list_rf_cv_mean],\n",
    "                ['Seat', 'Food', 'Staff', 'Entertainment'],\n",
    "                'Mean cross validation score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For accuracy score, even with different starting data sets, logistical regression is still the most adapted model for our 4 labels. Let's now see if we don't overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T13:09:43.530836Z",
     "start_time": "2020-01-16T13:09:43.320276Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_bars_model(['KNN', 'Logistic regression', 'Random forest'], \n",
    "                 [list_knn_cv_var, list_lr_cv_var, list_rf_cv_var],\n",
    "                ['Seat', 'Food', 'Staff', 'Entertainment'],\n",
    "                'Variance in cross validation scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if those results are really low for all of our models, we can see that random forest has the highest variance. This means that as the starting dataset changes, the accuracy score changes too (here the rate is low enought to consider it is just a normal variation).\n",
    "\n",
    "Logistic regression is the best model for this version, according to thoses measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V1 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T10:35:01.028653Z",
     "start_time": "2020-01-16T10:35:00.968574Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_MD_V1 = pd.read_csv(path + 'all_data_MD_V1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use the <span style= 'background:orange'> modele </span>  function, refer to the function notebook to see further information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enumerate all labels and models for predict\n",
    "\n",
    "liste_label = ['Cabin_Staff_Service', 'Seat_Comfort',\n",
    "               'Food_And_Beverages', 'Inflight_Entertainment']\n",
    "liste_model = ['lgbm', 'logistic_regression', 'knn', 'random_forest']\n",
    "\n",
    "# _A : Accuracy-score,   _E : RMSE,   _CV : Mean(cross-validated(accuracy-score)),   _VAR : Var(cross-validated(accuracy-score))\n",
    "types = ['_A', '_E', '_CV', '_VAR']\n",
    "\n",
    "col = []\n",
    "\n",
    "# Create a dataframe for all metrics/models and labels\n",
    "for model in liste_model:\n",
    "    for typ in types:\n",
    "        col.append(model + typ)\n",
    "\n",
    "tab_score = pd.DataFrame(np.zeros((len(liste_label), len(col))), index=[\n",
    "                         liste_label], columns=[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T11:26:32.617333Z",
     "start_time": "2020-01-17T11:12:48.154422Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate all model for all label and determine with many metrics the best model for the label. (average : 15 min)\n",
    "\n",
    "tab_score = all_model(all_data_MD_V1, liste_label, liste_model, tab_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T16:00:44.385839Z",
     "start_time": "2020-01-17T16:00:44.373821Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_scores_V1 = pd.read_csv(path + 'model_label_score_MD_V1.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T16:00:59.198411Z",
     "start_time": "2020-01-17T16:00:59.162389Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_scores_V1 = model_scores_V1.set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T16:03:14.714281Z",
     "start_time": "2020-01-17T16:03:14.682235Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_knn_accuracy = list(model_scores_V1['knn_A'])\n",
    "list_lr_accuracy = list(model_scores_V1['logistic_regression_A'])\n",
    "list_rf_accuracy = list(model_scores_V1['random_forest_A'])\n",
    "list_lgbm_accuracy = list(model_scores_V1['lgbm_A'])\n",
    "\n",
    "list_knn_mean_error = list(model_scores_V1['knn_E'])\n",
    "list_lr_mean_error =list(model_scores_V1['logistic_regression_E'])\n",
    "list_rf_mean_error = list(model_scores_V1['random_forest_E'])\n",
    "list_lgbm_mean_error = list(model_scores_V1['lgbm_E'])\n",
    "\n",
    "list_knn_cv_mean =list(model_scores_V1['knn_CV'])\n",
    "list_lr_cv_mean = list(model_scores_V1['logistic_regression_CV'])\n",
    "list_rf_cv_mean =list(model_scores_V1['random_forest_CV'])\n",
    "list_lgbm_cv_mean = list(model_scores_V1['lgbm_CV'])\n",
    "\n",
    "list_knn_cv_var = list(model_scores_V1['knn_VAR'])\n",
    "list_lr_cv_var = list(model_scores_V1['logistic_regression_VAR'])\n",
    "list_rf_cv_var = list(model_scores_V1['random_forest_VAR'])\n",
    "list_lgbm_cv_var = list(model_scores_V1['lgbm_VAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T16:01:18.199409Z",
     "start_time": "2020-01-17T16:01:17.943071Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_bars_model(['KNN', 'Logistic regression', 'Random forest', 'LGBM'], \n",
    "                 [list_knn_accuracy, list_lr_accuracy, list_rf_accuracy, list_lgbm_accuracy],\n",
    "                ['Seat', 'Food', 'Staff', 'Entertainment'],\n",
    "                'Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T16:02:23.815051Z",
     "start_time": "2020-01-17T16:02:23.582744Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_bars_model(['KNN', 'Logistic regression', 'Random forest', 'LGBM'], \n",
    "                 [list_knn_mean_error, list_lr_mean_error, list_rf_mean_error, list_lgbm_mean_error],\n",
    "                ['Seat', 'Food', 'Staff', 'Entertainment'],\n",
    "                'RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T16:03:30.416038Z",
     "start_time": "2020-01-17T16:03:30.175717Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_bars_model(['KNN', 'Logistic regression', 'Random forest', 'LGBM'], \n",
    "                 [list_knn_cv_mean, list_lr_cv_mean, list_rf_cv_mean, list_lgbm_cv_mean],\n",
    "                ['Seat', 'Food', 'Staff', 'Entertainment'],\n",
    "                'Mean cross validation score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T16:04:20.484065Z",
     "start_time": "2020-01-17T16:04:19.987403Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_bars_model(['KNN', 'Logistic regression', 'Random forest', 'LGBM'], \n",
    "                 [list_knn_cv_var, list_lr_cv_var, list_rf_cv_var, list_lgbm_cv_var],\n",
    "                ['Seat', 'Food', 'Staff', 'Entertainment'],\n",
    "                'Variance in cross validation scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see on Accuracy Score and Mean Cross Validation, best models are Random Forest and LGBM (96% good prediction). \n",
    "<br/> Their Variance are pretty low. Then, they don't overfit for every labels.\n",
    "<br/> Our resuts are pretty good, we will try adding features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V2 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T16:18:32.655948Z",
     "start_time": "2020-01-17T16:18:32.371595Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_MD_V2 = pd.read_csv(path + 'all_data_MD_V2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T16:19:17.737704Z",
     "start_time": "2020-01-17T16:19:17.717676Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enumerate all labels and models for predict\n",
    "\n",
    "liste_label = ['Cabin_Staff_Service', 'Seat_Comfort',\n",
    "               'Food_And_Beverages', 'Inflight_Entertainment']\n",
    "liste_model = ['lgbm', 'logistic_regression', 'knn', 'random_forest']\n",
    "\n",
    "# _A : Accuracy-score,   _E : RMSE,   _CV : Mean(cross-validated(accuracy-score)),   _VAR : Var(cross-validated(accuracy-score))\n",
    "types = ['_A', '_E', '_CV', '_VAR']\n",
    "\n",
    "col = []\n",
    "\n",
    "# Create a dataframe for all metrics/models and labels\n",
    "for model in liste_model:\n",
    "    for typ in types:\n",
    "        col.append(model + typ)\n",
    "\n",
    "tab_score = pd.DataFrame(np.zeros((len(liste_label), len(col))), index=[\n",
    "                         liste_label], columns=[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate all model for all label and determine with many metrics the best model for the label. (average : 15 min)\n",
    "\n",
    "tab_score = all_model(all_data_MD_V1, liste_label, liste_model, tab_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T16:20:33.344613Z",
     "start_time": "2020-01-17T16:20:33.332603Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_scores_V2 = pd.read_csv(path + 'model_label_score_MD_V2.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T16:21:13.883791Z",
     "start_time": "2020-01-17T16:21:13.847743Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_scores_V2 = model_scores_V2.set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T16:21:45.268140Z",
     "start_time": "2020-01-17T16:21:45.236102Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_knn_accuracy = list(model_scores_V2['knn_A'])\n",
    "list_lr_accuracy = list(model_scores_V2['logistic_regression_A'])\n",
    "list_rf_accuracy = list(model_scores_V2['random_forest_A'])\n",
    "list_lgbm_accuracy = list(model_scores_V2['lgbm_A'])\n",
    "\n",
    "list_knn_mean_error = list(model_scores_V2['knn_E'])\n",
    "list_lr_mean_error =list(model_scores_V2['logistic_regression_E'])\n",
    "list_rf_mean_error = list(model_scores_V2['random_forest_E'])\n",
    "list_lgbm_mean_error = list(model_scores_V2['lgbm_E'])\n",
    "\n",
    "list_knn_cv_mean =list(model_scores_V2['knn_CV'])\n",
    "list_lr_cv_mean = list(model_scores_V2['logistic_regression_CV'])\n",
    "list_rf_cv_mean =list(model_scores_V2['random_forest_CV'])\n",
    "list_lgbm_cv_mean = list(model_scores_V2['lgbm_CV'])\n",
    "\n",
    "list_knn_cv_var = list(model_scores_V2['knn_VAR'])\n",
    "list_lr_cv_var = list(model_scores_V2['logistic_regression_VAR'])\n",
    "list_rf_cv_var = list(model_scores_V2['random_forest_VAR'])\n",
    "list_lgbm_cv_var = list(model_scores_V2['lgbm_VAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T16:22:00.693870Z",
     "start_time": "2020-01-17T16:22:00.477580Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_bars_model(['KNN', 'Logistic regression', 'Random forest', 'LGBM'], \n",
    "                 [list_knn_accuracy, list_lr_accuracy, list_rf_accuracy, list_lgbm_accuracy],\n",
    "                ['Seat', 'Food', 'Staff', 'Entertainment'],\n",
    "                'Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T16:22:15.463365Z",
     "start_time": "2020-01-17T16:22:15.209340Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_bars_model(['KNN', 'Logistic regression', 'Random forest', 'LGBM'], \n",
    "                 [list_knn_mean_error, list_lr_mean_error, list_rf_mean_error, list_lgbm_mean_error],\n",
    "                ['Seat', 'Food', 'Staff', 'Entertainment'],\n",
    "                'RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T16:22:27.827733Z",
     "start_time": "2020-01-17T16:22:27.583378Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_bars_model(['KNN', 'Logistic regression', 'Random forest', 'LGBM'], \n",
    "                 [list_knn_cv_mean, list_lr_cv_mean, list_rf_cv_mean, list_lgbm_cv_mean],\n",
    "                ['Seat', 'Food', 'Staff', 'Entertainment'],\n",
    "                'Mean cross validation score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T16:22:37.826452Z",
     "start_time": "2020-01-17T16:22:37.591415Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_bars_model(['KNN', 'Logistic regression', 'Random forest', 'LGBM'], \n",
    "                 [list_knn_cv_var, list_lr_cv_var, list_rf_cv_var, list_lgbm_cv_var],\n",
    "                ['Seat', 'Food', 'Staff', 'Entertainment'],\n",
    "                'Variance in cross validation scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to V1, the KNN scores and linear regression does not change. However, there is a slight difference between LGBM and Random Forest; LGBM decreases its scores while Random Forest remains at the same scores. \n",
    "<br/>Two points to underline: \n",
    "- LGBM seems more sensitive to changes in the features, meaning our new features have som effect.\n",
    "- The features are not efficiant in a good way in our model. It would be necessary to look for new ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "259px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
