{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1>Groupe 5 - Prediction\n",
    "> Functions Notebook\n",
    "\n",
    "<span class=\"tocSkip\"></span>\n",
    "\n",
    "> *Authors : All*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Environment\" data-toc-modified-id=\"Environment-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Environment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Libraries-:\" data-toc-modified-id=\"Libraries-:-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Libraries :</a></span></li><li><span><a href=\"#Data-loading-:\" data-toc-modified-id=\"Data-loading-:-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Data loading :</a></span></li><li><span><a href=\"#Functions-:\" data-toc-modified-id=\"Functions-:-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Functions :</a></span></li></ul></li><li><span><a href=\"#Textual-analysis-approach\" data-toc-modified-id=\"Textual-analysis-approach-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Textual analysis approach</a></span></li><li><span><a href=\"#Metadata-analysis-approach\" data-toc-modified-id=\"Metadata-analysis-approach-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Metadata analysis approach</a></span></li><li><span><a href=\"#Both\" data-toc-modified-id=\"Both-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Both</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook's aim is to give access to all the functions needed to run the other DataFrames.\n",
    "\n",
    "It is separeted in 3 main parts : \n",
    "- The first one is the environnement setting, with imports of libraries and functions, and data loading.\n",
    "- The second one gathers functions used for the textual analysis approach. It means that thoses functions will be needed for each step of text analysis (pre-processing, model computing...)\n",
    "- The last one is the equivalent but for the metadata analysis approach.\n",
    "- Some functions can also be used by both groups, in this case, they will be in this fourth part.\n",
    "\n",
    "\n",
    "\n",
    "In every cell comments can be found about what the function is made for. \n",
    "\n",
    "Inside a function, one-line-comments (starting with #) are made to understand how the function works, and what is done during its run.\n",
    "\n",
    "More precise information can also be found for bigger functions, those are written between \"\"\"---\"\"\", and written in red.\n",
    "\n",
    "Some explaining cells will also be used sometimes in order to interprate, or conclude about the previous code cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:46.121992Z",
     "start_time": "2020-01-17T18:08:46.013850Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "from tqdm import tqdm_notebook\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import en_core_web_sm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import strip_punctuation\n",
    "from gensim.parsing.preprocessing import strip_short\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import scipy\n",
    "from textblob import TextBlob\n",
    "from textblob.en.sentiments import NaiveBayesAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import datetime\n",
    "import statistics\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:50.757690Z",
     "start_time": "2020-01-17T18:08:46.741478Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the english language model of spacy library\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Unused here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*Unused here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Textual analysis approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:50.841803Z",
     "start_time": "2020-01-17T18:08:49.661Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates and concatenates lemmas coming from a commentary.\n",
    "\n",
    "\n",
    "def lemmatize(sentence: str) -> str:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    s = nlp(sentence)\n",
    "    lemmatized = ''\n",
    "    for w in s:\n",
    "        lemmatized += w.lemma_ + ' '\n",
    "\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:50.857829Z",
     "start_time": "2020-01-17T18:08:50.132Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cleans the commentary by dropping useless data and by applying few functions of string management.\n",
    "\n",
    "\n",
    "def preprocessing(commentary: str) -> str:\n",
    "    # Droping 'Points positifs'-like strings\n",
    "    commentary = commentary.replace('Points positifs', ' ').replace(\n",
    "        'Points négatifs', ' ')  \n",
    "    # Droping 'Verified'-like strings\n",
    "    commentary = commentary.replace('Trip Verified', ' ').replace('Not Verified', ' ').replace(\n",
    "        'Verified Review', ' ').replace('|', ' ')  # delete \"Verified\"\n",
    "    # Converting text to lowercase\n",
    "    commentary = commentary.lower()\n",
    "    # Lemmatizing\n",
    "    commentary = lemmatize(commentary)\n",
    "    commentary = commentary.replace('-PRON-', ' ').replace(\"✅\", \" \")\n",
    "    return commentary.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:50.865835Z",
     "start_time": "2020-01-17T18:08:50.434Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Computes the tf-idf of a given column in a given DataFrame\n",
    "\n",
    "\n",
    "def TF_IDF_V0(data: pd.core.frame.DataFrame, COLUMN_NAME: str) -> pd.core.frame.DataFrame:\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        stop_words=\"english\", min_df=50)\n",
    "    X = vectorizer.fit_transform(list(data[COLUMN_NAME].values.astype('U')))\n",
    "    print('Taille : ', X.shape)\n",
    "    tf_idf_data = pd.DataFrame(\n",
    "        X.toarray(), columns=vectorizer.get_feature_names())\n",
    "    return (tf_idf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:50.873844Z",
     "start_time": "2020-01-17T18:08:50.690Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function importing data from xlsx file and returning its comments\n",
    "\n",
    "\n",
    "def database(data: pd.core.frame.DataFrame,\n",
    "             column: str) -> pd.core.frame.DataFrame:\n",
    "    # Dropping rows with empty review\n",
    "    data = data[data[\"Review\"].notnull()]\n",
    "    # Creating index\n",
    "    data['index'] = range(len(data)) \n",
    "    # Filling empty rows\n",
    "    data = data.fillna('')\n",
    "    sentences = data.loc[:, lambda data: [\"index\", column]]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:51.054109Z",
     "start_time": "2020-01-17T18:08:50.949946Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function importing a list of sentences and cleaning all of them by removing useless characters and converting each word to its word root\n",
    "\n",
    "\n",
    "def clean_data(sentences: pd.core.frame.DataFrame, column: str) -> pd.core.frame.DataFrame:\n",
    "    nlp_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "    sentences_clean = []\n",
    "    \n",
    "    for i in tqdm(sentences[\"index\"]):\n",
    "        \n",
    "        # Dropping 'Points positifs'-like strings\n",
    "        sentence = sentences[column][i].replace('Points positifs', ' ').replace(\n",
    "            'Points négatifs', ' ')  \n",
    "        \n",
    "         # Dropping 'Verified'-like strings\n",
    "        sentence = sentence.replace('Trip Verified', ' ').replace(\n",
    "            'Not Verified', ' ').replace('Verified Review', ' ') \n",
    "        \n",
    "        # Dropping link strings\n",
    "        sentence = re.sub(\n",
    "            r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', ' ', sentence) \n",
    "        \n",
    "        # Finding hashtag and doubled\n",
    "        sentence = sentence + ' ' + ' '.join(re.findall(r\"#(\\w+)\", sentence))\n",
    "        \n",
    "        # Finding @ and doubled\n",
    "        sentence = sentence + ' ' + \\\n",
    "            ' '.join(re.findall(r\"@(\\w+)\", sentence)) \n",
    "            \n",
    "        # Deleting punctuation\n",
    "        sentence = strip_punctuation(sentence)\n",
    "        \n",
    "        # Lower comments\n",
    "        semi_clean_sentence = ''\n",
    "        \n",
    "        # No-empty comments\n",
    "        comments = nlp_en(sentence.lower())  \n",
    "        if len(comments) != 0: \n",
    "            try:\n",
    "                # English comments\n",
    "                if detect(str(comments)) == 'en':  \n",
    "                    for token in comments:\n",
    "                        # Add lemmatizer\n",
    "                        semi_clean_sentence = semi_clean_sentence + token.lemma_ + ' '  \n",
    "                    # Deleting \"PRON\"\n",
    "                    semi_clean_sentence = semi_clean_sentence.replace(\n",
    "                        '-PRON-', '')  \n",
    "                    # Deleting shorts words\n",
    "                    semi_clean_sentence = remove_stopwords(\n",
    "                        strip_short(semi_clean_sentence))  \n",
    "                    sentences_clean.append([i, semi_clean_sentence])\n",
    "            except:\n",
    "                print(i)\n",
    "    return sentences_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:51.478658Z",
     "start_time": "2020-01-17T18:08:51.438629Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function creating the tf-idf matrix from cleaned sentences and creating a csv file\n",
    "\n",
    "\n",
    "def create_tfidf(sentences_clean: pd.core.frame.DataFrame, file: str):\n",
    "    # Recover comments\n",
    "    comments = [i[1] for i in sentences_clean]  \n",
    "    # Recover index\n",
    "    index = [i[0] for i in sentences_clean]  \n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        stop_words=\"english\", min_df=0.15)  \n",
    "    X = vectorizer.fit_transform(comments)\n",
    "\n",
    "    # Creation of matrice\n",
    "    M = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    # Add comments to tfidf\n",
    "    tfidf = np.concatenate((pd.DataFrame(index), pd.DataFrame(\n",
    "        comments), M), axis=1)  \n",
    "    col = vectorizer.get_feature_names()\n",
    "    # Renaming columns\n",
    "    col = ['index', 'commentaire'] + col  \n",
    "    \n",
    "    # Saving matrix\n",
    "    pd.DataFrame(tfidf, columns=col).set_index('index').to_csv(\n",
    "        \"ALL_DATA_Processed_15.csv\", sep=\",\")  \n",
    "\n",
    "    print('Matrice TF-IDF de ' + file + ' enregistrée')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:51.847299Z",
     "start_time": "2020-01-17T18:08:51.827285Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nb_word_comment(data: pd.core.frame.DataFrame,\n",
    "                    column: str) -> pd.core.frame.DataFrame:\n",
    "  # Calculation of word count per commment\n",
    "  # Out : dataframe plus a column containing the word count\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    liste_comm = []\n",
    "    size = []\n",
    "    for i in range(len(df[column])):\n",
    "        comm = df[column][i].split()\n",
    "        size.append(len(comm))\n",
    "    df['nb_word_comment'] = size\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:52.273649Z",
     "start_time": "2020-01-17T18:08:52.249618Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nbpunctuation(data: pd.core.frame.DataFrame, punct: str,\n",
    "                  columns: str) -> pd.core.frame.DataFrame:\n",
    "  # Calculation of the punctuation count per commment\n",
    "  # Out : dataframe plus a column with the punctuation count\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    nbpunct = []\n",
    "    for i in range(len(df[columns])):\n",
    "        comment = df[columns][i]\n",
    "        cpt = 0\n",
    "        for j in range(len(comment)):\n",
    "            if comment[j] == punct:\n",
    "                cpt += 1\n",
    "        nbpunct.append(cpt)\n",
    "    df[punct] = nbpunct\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:52.586064Z",
     "start_time": "2020-01-17T18:08:52.566040Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_analyse(\n",
    "    df: pd.DataFrame, review: str) -> pd.core.frame.DataFrame:\n",
    "  # Out : dataframe with sentiment analysis features in new colum\n",
    "  # polarity and subjectivity from TextBlob module\n",
    "  # polarity (neg, neu, pos, compound) from Vader\n",
    "  # References: https://www.nltk.org/api/nltk.sentiment.html\n",
    "\n",
    "    df[\"polarity\"] = df[review].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "    df[\"subjectivity\"] = df[review].apply(\n",
    "        lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    df[\"sentiments\"] = df[review].apply(lambda x: sid.polarity_scores(x))\n",
    "    df = pd.concat([df.drop([\"sentiments\"], axis=1),\n",
    "                    df[\"sentiments\"].apply(pd.Series)], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:53.016550Z",
     "start_time": "2020-01-17T18:08:52.972495Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nbword(data, word: str, columns: str) -> pd.core.frame.DataFrame:\n",
    "  # Calculation of the word count per commment\n",
    "  # Out : dataframe plus a column containing the word count\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    nbword = []\n",
    "    word = word.lower()\n",
    "    for i in range(len(df[columns])):\n",
    "        comment = df[columns][i].split()\n",
    "        comment = [item.replace(\".\", \"\") for item in comment]\n",
    "        cpt = 0\n",
    "        for j in range(len(comment)):\n",
    "            if comment[j].lower() == word:\n",
    "                cpt += 1\n",
    "        nbword.append(cpt)\n",
    "    df[word] = nbword\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:53.320960Z",
     "start_time": "2020-01-17T18:08:53.314Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nblistword(data: pd.core.frame.DataFrame,\n",
    "               listword: list, columns: str,\n",
    "               name: str) -> pd.core.frame.DataFrame:\n",
    "\n",
    "   # Calculation of the word count per commment, words are given in the list\n",
    "   # Out : dataframe plus a column with the word count\n",
    "\n",
    "    for colname in listword:\n",
    "        data = nbword(data, colname, columns)\n",
    "    data[\"nb_word_\" + name] = 0\n",
    "    print(data)\n",
    "    for colname in listword:\n",
    "        data[\"nb_word_\" + name] = data[\"nb_word_\" + name] + data[colname]\n",
    "        data.drop([colname], axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:53.613347Z",
     "start_time": "2020-01-17T18:08:53.604Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nblisteponctuation(data: pd.core.frame.DataFrame,\n",
    "                       listpoct: list, columns: str,\n",
    "                       name: str) -> pd.core.frame.DataFrame:\n",
    "\n",
    "  # Calculation of the punctuation count available in the list, per commment\n",
    "  # Out : dataframe plus a column with the punctuation count\n",
    "\n",
    "    for colname in listpoct:\n",
    "        data = nbpunctuation(data, colname, columns)\n",
    "    data[\"nb_ponct_\" + name] = 0\n",
    "    print(data)\n",
    "    for colname in listpoct:\n",
    "        data[\"nb_ponct_\" + name] = data[\"nb_ponct_\" + name] + data[colname]\n",
    "        data.drop([colname], axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:54.158074Z",
     "start_time": "2020-01-17T18:08:53.863Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nb_sentence(data: pd.core.frame.DataFrame,\n",
    "                column: str) -> pd.core.frame.DataFrame:\n",
    "  # Calculation of the sentence count per commment\n",
    "  # Out : dataframe plus a column with the sentence count\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    nbsentence = []\n",
    "    for i in range(len(df[column])):\n",
    "        phrase = df[column][i].split('.')\n",
    "        nbsentence.append(len(phrase))\n",
    "    df['nbsentence'] = nbsentence\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T11:02:53.534681Z",
     "start_time": "2020-01-13T11:02:53.528170Z"
    }
   },
   "source": [
    "# Metadata analysis approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:55.007198Z",
     "start_time": "2020-01-17T18:08:54.931101Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applying different functions on the 'Aircraft_Type' column in order to have the\n",
    "# same writting between dataframes\n",
    "\n",
    "\n",
    "def homogenize_aircraft(df: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    # Type str\n",
    "    df['Aircraft_Type'] = df['Aircraft_Type'].astype(str)\n",
    "    # Lower case\n",
    "    df['Aircraft_Type'] = df['Aircraft_Type'].apply(lambda x: x.lower())\n",
    "    # Deleting rows corresponding to flights with connexions\n",
    "    df = df[~df['Aircraft_Type'].str.contains('/|,|&|and|\\+|then', na=False)]\n",
    "    # Deleting spaces and '-'\n",
    "    df['Aircraft_Type'] = df['Aircraft_Type'].apply(\n",
    "        lambda x: re.sub(\"(\\s|-)\", \"\", x))\n",
    "    # The 6 next commands replace some strings by other ones\n",
    "    df['Aircraft_Type'] = df['Aircraft_Type'].apply(\n",
    "        lambda x: x.replace('embraer', 'e'))\n",
    "    df['Aircraft_Type'] = df['Aircraft_Type'].apply(\n",
    "        lambda x: x.replace('ee', 'e'))\n",
    "    df['Aircraft_Type'] = df['Aircraft_Type'].apply(\n",
    "        lambda x: x.replace('airbus', 'a'))\n",
    "    df['Aircraft_Type'] = df['Aircraft_Type'].apply(\n",
    "        lambda x: x.replace('aa', 'a'))\n",
    "    df['Aircraft_Type'] = df['Aircraft_Type'].apply(\n",
    "        lambda x: x.replace('boeing', 'b'))\n",
    "    df['Aircraft_Type'] = df['Aircraft_Type'].apply(\n",
    "        lambda x: x.replace('bb', 'b'))\n",
    "    # Deleting strings containing format 'v' + number\n",
    "    df['Aircraft_Type'] = df['Aircraft_Type'].apply(\n",
    "        lambda x: re.sub(\"v[0-9].*$\", \"\", x))\n",
    "    # Keeping only format letter + numbers\n",
    "    df['Aircraft_Type'] = df['Aircraft_Type'].apply(\n",
    "        lambda x: re.sub(\".+?(?=[a-z]{1}[0-9]{1,})\", '', x))\n",
    "    # Deleting everything that is after a parenthesis\n",
    "    df['Aircraft_Type'] = df['Aircraft_Type'].apply(\n",
    "        lambda x: re.sub(\"(\\().*$\", \"\", x))\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:55.431792Z",
     "start_time": "2020-01-17T18:08:55.415769Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applying different functions on a given column (the one explaining the cabin class)\n",
    "# in order to have the same writtings between dataframes\n",
    "\n",
    "\n",
    "def homogenize_cabin_class(df: pd.core.frame.DataFrame,\n",
    "                           COLUMN_NAME: str) -> pd.core.frame.DataFrame:\n",
    "    # Deleting word 'Class'\n",
    "    df[COLUMN_NAME] = df[COLUMN_NAME].apply(\n",
    "        lambda x: x.replace(' Class', ''))\n",
    "    # Lower\n",
    "    df[COLUMN_NAME] = df[COLUMN_NAME].apply(\n",
    "        lambda x: x.lower())\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:55.808263Z",
     "start_time": "2020-01-17T18:08:55.792264Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applying different functions on a given column (the one explaining the the airline name)\n",
    "# in order to have the same writtings between dataframes\n",
    "\n",
    "\n",
    "def homogenize_airline(df : pd.core.frame.DataFrame\n",
    "                       , COLUMN_NAME: str) -> pd.core.frame.DataFrame:\n",
    "    # Lower case\n",
    "    df[COLUMN_NAME] = df[COLUMN_NAME].apply(\n",
    "        lambda x: x.lower())\n",
    "    # Deleting spaces and '-'\n",
    "    df[COLUMN_NAME] = df[COLUMN_NAME].apply(\n",
    "        lambda x: re.sub(\"(\\s|-)\", \"\", x))\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:56.221762Z",
     "start_time": "2020-01-17T18:08:56.181726Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merging DataFrames coming from the SEATGURU_INFO_AIRCRAFT.csv and the ALL_DATA.xslsx files\n",
    "# in order to get only complete rows\n",
    "\n",
    "\n",
    "def merge_all_data_seatguru(df_all_data: pd.core.frame.DataFrame,\n",
    "                            seatguru: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    # Merging\n",
    "    new_df = pd.merge(df_all_data, seatguru,  how='left',\n",
    "                      left_on=['Aircraft_Type', 'Airline_Name', 'Cabin_Class'],\n",
    "                      right_on=['Aircraft_Type', 'Airline_name', 'Category'])\n",
    "\n",
    "    # Deleting rows from the new DataFrame that are not 'complete'\n",
    "    # No Aircraft Type\n",
    "    new_df = new_df[new_df['Aircraft_Type'] != '']\n",
    "    # No 'Total_seat' (because this one is representative of the seatguru file)\n",
    "    new_df = new_df[~new_df['Total_seat'].isnull()]\n",
    "    # No 'Review' (because this one is representative of the all_data file)\n",
    "    new_df = new_df[~new_df['Data_Source_x'].isnull()]\n",
    "\n",
    "    # Dropping useless columns\n",
    "    new_df = new_df.drop(['Data_Source_y',\n",
    "                          'Airline_name',\n",
    "                         'Category'], axis=1)\n",
    "\n",
    "    # Renaming columns that have '_x' or '_y' at end because of merge\n",
    "    new_df = new_df.rename(columns={\n",
    "                           \"Data_Source_x\": \"Data_Source\",\n",
    "                           \"Category_x\": \"Category\",\n",
    "                           \"Seat_Type_y\": \"Seat_Type\"})\n",
    "\n",
    "    return(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:56.937267Z",
     "start_time": "2020-01-17T18:08:56.881191Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform a string date into a standard format by trying each date format.\n",
    "# If you want to add a format, add a try/except in the last except\n",
    "\n",
    "\n",
    "def format_date(date: str) -> datetime.datetime:\n",
    "    date_str = date\n",
    "    m = \"nc\"\n",
    "\n",
    "    if date_str != \"nc\":\n",
    "        date_str = str(date_str)\n",
    "        # Does not work for August\n",
    "        if (\"August\" not in date_str):\n",
    "            date_str = date_str.replace(\"st\", \"\").replace(\"th\", \"\")\\\n",
    "                .replace(\"nd\", \"\").replace(\"rd\", \"\").replace(\" Augu \", \" Aug \")\n",
    "        # Transofrm string considering its format\n",
    "        try:\n",
    "            m = datetime.datetime.strptime(date_str, \"%d %B %Y\")\n",
    "        except ValueError:\n",
    "            try:\n",
    "                m = datetime.datetime.strptime(date_str, \"%d %b %Y\")\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    m = datetime.datetime.strptime(date_str, \"%Y/%m/%d\")\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        m = datetime.datetime\\\n",
    "                            .strptime(date_str, \"%d/%m/%Y %H:%M:%S\")\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            m = datetime.datetime\\\n",
    "                                .strptime(date_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "                        except ValueError:\n",
    "                            try:\n",
    "                                m = datetime.datetime.strptime(date_str,\n",
    "                                                               \"%d %m %Y\")\n",
    "                            except ValueError:\n",
    "                                try:\n",
    "                                    m = datetime.datetime.strptime(date_str,\n",
    "                                                                   \"%B %Y\")\n",
    "                                except ValueError:\n",
    "                                    # HERE ADD A FORMAT TO CHECK\n",
    "                                    print(\"Format not recognised. \\nConsider \"\n",
    "                                          \"adding a date format \"\n",
    "                                          \"in the function \\\"format_date\\\".\")\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:57.491841Z",
     "start_time": "2020-01-17T18:08:57.471818Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to select the class according to the seat type\n",
    "\n",
    "\n",
    "def select_class_from_seat(classe: pd.core.frame.Series, seat_type: pd.core.frame.Series) -> pd.core.frame.Series:\n",
    "\n",
    "    # Replace only None values\n",
    "    if classe == 'nc':\n",
    "        if \"Economy Class\" in seat_type:\n",
    "            classe = \"Economy Class\"\n",
    "        elif \"Premium Economy\" in seat_type:\n",
    "            classe = \"Premium Economy\"\n",
    "        elif \"Business Class\" in seat_type:\n",
    "            classe = \"Business Class\"\n",
    "        elif \"World Traveller Plus\" in seat_type:\n",
    "            classe = \"Premium Economy\"\n",
    "    return classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:57.926442Z",
     "start_time": "2020-01-17T18:08:57.910420Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Chi-square computing\n",
    "\n",
    "\n",
    "def test_khi_deux(df: pd.core.frame.DataFrame, col1: str, col2: str) -> float:\n",
    "\n",
    "    df = pd.crosstab(df[col1], df[col2])\n",
    "    chisq, p_value, dot, expected = stats.chi2_contingency(df)\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:58.371842Z",
     "start_time": "2020-01-17T18:08:58.335813Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Chi-square compputing then decision. Compares one column with every columns and keeps p-value < 1%\n",
    "\n",
    "\n",
    "def compare_colonne(df : pd.core.frame.DataFrame, COL : str) -> list:\n",
    "\n",
    "    # delete empty values\n",
    "    filter_df = df[df[COL].notnull()]\n",
    "    keep_column = []\n",
    "    columns_df = filter_df.columns\n",
    "    for column in columns_df:\n",
    "\n",
    "        # Check if a column has more than two different values\n",
    "        VALUES = filter_df[column].nunique()\n",
    "        if VALUES > 1 and column != COL:\n",
    "            p_value = test_khi_deux(filter_df, COL, column)\n",
    "\n",
    "            # Keeps the columns significantly dependent\n",
    "            if p_value < 0.01:\n",
    "                keep_column.append([column, p_value])\n",
    "\n",
    "    return keep_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:58.756358Z",
     "start_time": "2020-01-17T18:08:58.712297Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Complete \"Cabin_Class\" column\n",
    "\n",
    "\n",
    "def clean_Cabin_Class(df: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "\n",
    "    # Replace all Nan values by \"nc\" (easier)\n",
    "    df['Cabin_Class'] = df['Cabin_Class'].fillna(\"nc\")\n",
    "    df['Seat_Type'] = df['Seat_Type'].fillna(\"nc\")\n",
    "    df['Type_Of_Traveller'] = df['Type_Of_Traveller'].fillna(\"nc\")\n",
    "\n",
    "    # Replace values function\n",
    "    df['Cabin_Class'] = df.apply(lambda df: select_class_from_seat(\n",
    "        df['Cabin_Class'], df['Seat_Type']), axis=1)\n",
    "\n",
    "    # Retrieves the most frequent value according to a constraint\n",
    "    for i in range(len(df['Type_Of_Traveller'])):\n",
    "        if df['Cabin_Class'][i] == \"nc\" and df['Type_Of_Traveller'][i] != \"nc\":\n",
    "            mode = statistics.mode(\n",
    "                df[df['Type_Of_Traveller'] == df['Type_Of_Traveller'][i]]['Cabin_Class'])\n",
    "            df['Cabin_Class'][i] = mode\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:59.216969Z",
     "start_time": "2020-01-17T18:08:59.180922Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Complete \"Value_For_Money\" column\n",
    "\n",
    "\n",
    "def clean_Value_For_Money(df: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "\n",
    "    # Create an X_train and Y_train for predictions. Binarize X_train. Moreover, we keep not null values lines for value_for_money\n",
    "    X_train = df[df['Value_For_Money'].notnull(\n",
    "    )][['Cabin_Class', 'Overall_Customer_Rating', 'Recommended']]\n",
    "    X_train = pd.get_dummies(X_train)\n",
    "\n",
    "    Y_train = df[df['Value_For_Money'].notnull()]['Value_For_Money']\n",
    "\n",
    "    # KNN neighbors=20\n",
    "    neigh = KNeighborsClassifier(20).fit(X_train, Y_train)\n",
    "    predict = neigh.predict(pd.get_dummies(\n",
    "        df[['Cabin_Class', 'Overall_Customer_Rating', 'Recommended']]))\n",
    "    df['predict'] = pd.Series(predict)\n",
    "\n",
    "    # Replace Nan values by the prediction\n",
    "    df['Value_For_Money'] = df.apply(lambda row: row['predict'] if np.isnan(\n",
    "        row['Value_For_Money']) else row['Value_For_Money'], axis=1)\n",
    "\n",
    "    del df['predict']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:59.650430Z",
     "start_time": "2020-01-17T18:08:59.630402Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Complete \"Type_Of_Traveller\" column thanks to Cabin_class column\n",
    "\n",
    "\n",
    "def clean_Type_Of_Traveller(df: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "\n",
    "    test = df[df['Type_Of_Traveller'] == \"nc\"]\n",
    "    mode = {}\n",
    "    \n",
    "    # Comparing with cabin class value, then getting the most present value in type of traveller\n",
    "    for unique_value in df['Cabin_Class'].unique():\n",
    "        if unique_value != \"nc\":\n",
    "            mode[unique_value] = statistics.mode(\n",
    "                df[(df['Cabin_Class'] == unique_value) & (df['Type_Of_Traveller'] != \"nc\")]['Type_Of_Traveller'])\n",
    "\n",
    "    df['Type_Of_Traveller'] = df.apply(lambda row: mode[row['Cabin_Class']] if row['Type_Of_Traveller']\n",
    "                                       == \"nc\" and row['Cabin_Class'] != \"nc\" else row['Type_Of_Traveller'], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:08:59.987880Z",
     "start_time": "2020-01-17T18:08:59.971886Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gives percentage of missing values by column\n",
    "\n",
    "\n",
    "def pourcent_col_missing(df: pd.core.frame.DataFrame) -> dict:\n",
    "\n",
    "    # Take all columns name\n",
    "    column = df.columns\n",
    "    missing_values = {}\n",
    "\n",
    "    # Calculate missing values for all column\n",
    "    for col in column:\n",
    "        missing_values[col] = 100 * len(df[df[col].isnull()][col]) / len(df)\n",
    "\n",
    "    return missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:09:00.453347Z",
     "start_time": "2020-01-17T18:09:00.437332Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deletes columns with many Nan values\n",
    "\n",
    "\n",
    "def select_col_nal(df: pd.core.frame.DataFrame, Percent: int) -> pd.core.frame.DataFrame:\n",
    "\n",
    "    # percent by columns\n",
    "    percent_columns = pourcent_col_missing(df)\n",
    "\n",
    "    # keep column name who has less than percentage Nan values\n",
    "    var_percent = [key for key, val in percent_columns.items()\n",
    "                   if val < Percent]\n",
    "\n",
    "    df = df[var_percent]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:09:00.813831Z",
     "start_time": "2020-01-17T18:09:00.801849Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate missing values by ligne\n",
    "\n",
    "\n",
    "def pourcent_row_missing(df: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    \n",
    "    # percentage of missing values by row\n",
    "    df['percent_missing'] = (df.isnull().sum(axis=1))/len(list(df))*100\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:09:01.254546Z",
     "start_time": "2020-01-17T18:09:01.230515Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete rows with many Nan values\n",
    "\n",
    "\n",
    "def select_lign_nal(df: pd.core.frame.DataFrame, Percent: int) -> pd.core.frame.DataFrame:\n",
    "\n",
    "    # missing values by row\n",
    "    df = pourcent_row_missing(df)\n",
    "    list_var = list(df[df['percent_missing'] > Percent].index)\n",
    "    list_var = sorted(list_var, reverse=True)\n",
    "\n",
    "    # Delete row above the given percentage\n",
    "    for ligne in list_var:\n",
    "        df = df.drop([ligne], inplace=True)\n",
    "\n",
    "    del df['percent_missing']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:09:01.732892Z",
     "start_time": "2020-01-17T18:09:01.720878Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate number of modality by column\n",
    "\n",
    "\n",
    "def nb_moda(df: pd.core.frame.DataFrame) -> dict:\n",
    "\n",
    "    # Takes all columns name\n",
    "    column = df.columns\n",
    "    nunique_value = {}\n",
    "\n",
    "    # Calculates number of modality for all column\n",
    "    for col in column:\n",
    "        nunique_value[col] = df[col].nunique()\n",
    "\n",
    "    return nunique_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:09:02.169476Z",
     "start_time": "2020-01-17T18:09:02.153459Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete columns with low modality\n",
    "\n",
    "\n",
    "def select_moda_nal(df: pd.core.frame.DataFrame, nb_mod: int) -> pd.core.frame.DataFrame:\n",
    "\n",
    "    # takes number of modality by column\n",
    "    moda = nb_moda(df)\n",
    "\n",
    "    # keeps only variable with number of madality between 1 and nb_mod\n",
    "    good_mod = [key for key, val in moda.items() if val < nb_mod and val > 1]\n",
    "    df = df[good_mod]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:09:02.541310Z",
     "start_time": "2020-01-17T18:09:02.525293Z"
    }
   },
   "outputs": [],
   "source": [
    "# Binarize all columns\n",
    "\n",
    "\n",
    "def binarized(df: pd.core.frame.DataFrame, liste: list, var: str) -> pd.core.frame.DataFrame:\n",
    "\n",
    "    for elt in liste:\n",
    "        if elt != var:\n",
    "            # Transform all in int column\n",
    "            df = pd.get_dummies(df, columns=[elt], dummy_na=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:09:03.437922Z",
     "start_time": "2020-01-17T18:09:03.289727Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determine best score for one column on every step and complete the column on every step\n",
    "\n",
    "\n",
    "def score(df: pd.core.frame.DataFrame, step: int, tab_score: pd.core.frame.DataFrame, drop_var: list) -> tuple:\n",
    "    best_score = 0.0\n",
    "    column = df.columns\n",
    "\n",
    "    for col in column:\n",
    "\n",
    "        # Binarized dataframe except one column\n",
    "        df_binari = binarized(df, column, col)\n",
    "        df_bin = df_binari[df_binari[col].notnull()]\n",
    "        df_nan = df_binari[df_binari[col].isnull()]\n",
    "\n",
    "        model = LogisticRegression()\n",
    "        cv_score = []\n",
    "\n",
    "        # Logistic Regression with cross validation (KFold)\n",
    "        kf = KFold(n_splits=3)\n",
    "        for train_index, test_index in kf.split(df_bin):\n",
    "            X_train, X_test = df_bin.drop(col, axis=1).iloc[list(\n",
    "                train_index)], df_bin.drop(col, axis=1).iloc[list(test_index)]\n",
    "            y_train, y_test = df_bin[col].iloc[list(\n",
    "                train_index)], df_bin[col].iloc[list(test_index)]\n",
    "            model.fit(X_train, y_train)\n",
    "            prediction_cv = model.predict(X_test)\n",
    "            cv_score.append(accuracy_score(prediction_cv, y_test))\n",
    "\n",
    "        mean_cv_score = np.mean(cv_score)\n",
    "        var_cv_score = np.var(cv_score)\n",
    "\n",
    "        # Determine the best score for all variable and we predict the best score for a column. Be careful, if a variable has been complete, we don't complete it again.\n",
    "        if (mean_cv_score > best_score) and (col not in drop_var):\n",
    "            best_score = mean_cv_score\n",
    "            prediction = model.predict(df_nan.drop(col, axis=1))\n",
    "            column_select = col\n",
    "            df_nan_loc = df_nan\n",
    "\n",
    "        # Complete the empty Dataframe\n",
    "        tab_score[col].iloc[step] = mean_cv_score\n",
    "\n",
    "    # Complete all nan values on the original DataFrame\n",
    "    row = df_nan_loc.index.values\n",
    "    predict_value = {}\n",
    "\n",
    "    for index, valeur in zip(row, prediction):\n",
    "        predict_value[index] = valeur\n",
    "\n",
    "    df[column_select] = df[column_select].reset_index().apply(lambda row: predict_value[row['index']]\n",
    "                                                              if row['index'] in predict_value else row[column_select], axis=1)\n",
    "\n",
    "    return tab_score, df, column_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:09:03.919730Z",
     "start_time": "2020-01-17T18:09:03.899703Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace Nan values by linear regression prediction\n",
    "\n",
    "\n",
    "def fill_dataset(df: pd.core.frame.DataFrame) -> tuple:\n",
    "\n",
    "    # Creating an empty dataframe that will be completed with all columns\n",
    "    var_list = []\n",
    "    tab_score = pd.DataFrame(\n",
    "        np.zeros((len(df.columns), len(df.columns))), columns=df.columns)\n",
    "\n",
    "    # Complete all Nan values and it deserve for taking parameters decision\n",
    "    for i in range(len(df.columns)):\n",
    "        tab_score, df, column = score(df, i, tab_score, var_list)\n",
    "        var_list.append(column)\n",
    "        \n",
    "    return df, tab_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:09:04.340288Z",
     "start_time": "2020-01-17T18:09:04.312252Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Changes the units of the seat angles to 'deg' for degrees, 'in' for inches.\n",
    "\n",
    "\n",
    "def modif_recline_degrees(recline: str) -> str:\n",
    "\n",
    "    # Select the column 'Recline' of the DataFrame associated with the file SEATGURU_INFO_AIRCRAFT.csv\n",
    "    if recline != 'nc':\n",
    "        recline = str(recline).lower()\n",
    "        recline = recline.replace('inches', 'in').replace('inch', 'in').replace(\n",
    "            '\"', ' in').replace('degrees', 'deg').replace('degree', 'deg')\n",
    "        if ('deg' not in recline and 'in' not in recline):\n",
    "            str_list = re.findall(r'\\d+', recline)\n",
    "            int_list = [int(s) for s in str_list]\n",
    "            nb = np.mean(int_list)\n",
    "            if nb < 90:\n",
    "                recline = recline + ' in'\n",
    "            else:\n",
    "                recline = recline + ' deg'\n",
    "\n",
    "    return recline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:09:04.865705Z",
     "start_time": "2020-01-17T18:09:04.849676Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Give the same mesure for inc and degree\n",
    "\n",
    "\n",
    "def get_recline_percent(recline: str) -> float:\n",
    "    if recline != 'nc':\n",
    "        recline = modif_recline_degrees(recline)\n",
    "        list_string = re.findall(r'\\d+', recline)\n",
    "        list_int = [int(n) for n in list_string]\n",
    "        if 'in' in recline:\n",
    "            recline = (np.mean(list_int)/18)*100\n",
    "        elif 'deg' in recline:\n",
    "            recline = (np.mean(list_int)/180)*100\n",
    "            \n",
    "    return recline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:09:05.264713Z",
     "start_time": "2020-01-17T18:09:05.256700Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Complete the width max by the width min\n",
    "\n",
    "\n",
    "def fill_width_max(width_min: float, width_max: float) -> float:\n",
    "    if width_max is None : \n",
    "        width_max = width_min\n",
    "        \n",
    "    return width_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:09:05.876313Z",
     "start_time": "2020-01-17T18:09:05.864298Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the proportion of the seat occuped by passenger\n",
    "\n",
    "\n",
    "def filling_percent(total_seat: float, count: float) -> float:\n",
    "    if total_seat != 'nc' and count != 'nc':\n",
    "        fill = (count/total_seat)*100\n",
    "        \n",
    "    return fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:09:06.359353Z",
     "start_time": "2020-01-17T18:09:06.347340Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gives the difference the 2 given note\n",
    "\n",
    "\n",
    "def rating_overall_rating_gap(rating: float, overall_rating: float) -> float:\n",
    "    if rating != 'nc' and overall_rating != 'nc':\n",
    "        gap = abs(rating - overall_rating)\n",
    "        \n",
    "    return gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:09:06.878778Z",
     "start_time": "2020-01-17T18:09:06.850709Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function take best parameters for both model. Be careful, this function take so much time\n",
    "# As this function is quite slow, grid searchs are now commented (we already know best parameters)\n",
    "\n",
    "def best_parameter(model_type: str, X_train: pd.core.frame.DataFrame, Y_train: pd.core.frame.DataFrame) -> list:\n",
    "    \n",
    "    list_best_parameter = []\n",
    "    # Determine better parameter for KNN\n",
    "    if model_type == 'knn':\n",
    "        list_best_parameter = [1]\n",
    "        '''param_grid2 = {\n",
    "            'n_neighbors': range(1, 20, 5)\n",
    "        }\n",
    "\n",
    "        KNN = KNeighborsClassifier()\n",
    "        gs = GridSearchCV(\n",
    "            estimator=KNN, param_grid=param_grid2, cv=3, n_jobs=-1)\n",
    "        gs.fit(X_train, Y_train)\n",
    "\n",
    "        list_best_parameter.append(gs.best_params_.get('n_neighbors'))'''\n",
    "    \n",
    "    # Determine better parameters for Random Forest\n",
    "    elif model_type == 'random_forest':\n",
    "        list_best_parameter = [50,42,100]\n",
    "        '''param_grid1 = {\n",
    "            'max_depth': [30, 40],\n",
    "            'random_state': [42],\n",
    "            'n_estimators': [100]\n",
    "        }\n",
    "        \n",
    "        randomF = RandomForestRegressor()\n",
    "        gs = GridSearchCV(estimator=randomF, param_grid=param_grid1, cv=3, n_jobs=-1)\n",
    "        gs.fit(X_train,Y_train)\n",
    "        list_best_parameter.append(gs.best_params_.get('max_depth'))\n",
    "        list_best_parameter.append(gs.best_params_.get('random_state'))\n",
    "        list_best_parameter.append(gs.best_params_.get('n_estimators'))'''\n",
    "    \n",
    "    #Determine better parameters for lgbm\n",
    "    elif model_type == 'lgbm':\n",
    "        list_best_parameter = [2500, 17, 100, 200]\n",
    " \n",
    "    '''param={\n",
    "            'num_leaves': [2500],\n",
    "            'max_depth': [15,16,17],\n",
    "            'min_data_in_leaf': [100,400],\n",
    "            'n_estimators':[100,150,200]\n",
    "    }\n",
    "    lgb_train = lgb.Dataset(X_train, Y_train, categorical_feature=param)\n",
    "    lgb_eval = lgb.Dataset(X_test, Y_test, reference=lgb_train)\n",
    "    gbm = lgb.LGBMClassifier('gbdt',lgb_train)\n",
    "\n",
    "\n",
    "    gs=GridSearchCV(estimator=gbm,param_grid=param,cv=3, n_jobs=-1, verbose=1)\n",
    "    gs.fit(X_train,Y_train)\n",
    "\n",
    "    list_best_parameter.append(gs.best_params_.get('max_depth'))\n",
    "    list_best_parameter.append(gs.best_params_.get('random_state'))\n",
    "    list_best_parameter.append(gs.best_params_.get('n_estimators')'''\n",
    "    \n",
    "    return list_best_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:09:07.454072Z",
     "start_time": "2020-01-17T18:09:07.442056Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function will drop label that we don't predict\n",
    "\n",
    "\n",
    "def labels_todrop(label_predict: list) -> list:\n",
    "\n",
    "    liste_label = ['Cabin_Staff_Service', 'Seat_Comfort',\n",
    "                   'Food_And_Beverages', 'Inflight_Entertainment']\n",
    "    liste_label.remove(label_predict)\n",
    "\n",
    "    return liste_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:09:07.887972Z",
     "start_time": "2020-01-17T18:09:07.875931Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate X and y (column for predicting)\n",
    "\n",
    "\n",
    "def create_XY(df: pd.core.frame.DataFrame, predict: 'str') -> tuple:\n",
    "\n",
    "    y = df[predict]\n",
    "    del df[predict]\n",
    "    X = df\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:09:08.493541Z",
     "start_time": "2020-01-17T18:09:08.413434Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Result accuracy, rmse, cross_val mean and cross-val var for a model. Deserve for taking the best model.\n",
    "\n",
    "\n",
    "def modele(df : pd.core.frame.DataFrame, label_predict : str, model_type : str, percent_missing_col : int, nb_moda : int) -> str:\n",
    "\n",
    "    \n",
    "    # Clear empty column or little number of value\n",
    "    df = select_col_nal(df, percent_missing_col)\n",
    "    \n",
    "    df = select_moda_nal(df, nb_moda)\n",
    "    \n",
    "    \n",
    "    # Keep label for predict\n",
    "    unnecessary_label = labels_todrop(label_predict)\n",
    "    \n",
    "    df_drop = df.drop(unnecessary_label, axis=1, inplace = True)\n",
    "    \n",
    "    df = df[df[label_predict].notnull()]\n",
    "    \n",
    "    # Just binarized string column\n",
    "    if model_type != 'lgbm':\n",
    "        bin_var = df.select_dtypes(include=['object']).columns\n",
    "        df = binarized(df, bin_var, label_predict)\n",
    "        \n",
    "        # Create X and Y (train and test too) for the prediction\n",
    "        X, y = create_XY(df, label_predict)\n",
    "        X = df.fillna(-1)\n",
    "    else:\n",
    "        X, y, categ = prepare_data_non_binarized(df, label_predict)\n",
    "    \n",
    "   \n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "    # Determine best parameters for model\n",
    "    list_best_parameter = []\n",
    "    if (model_type == 'knn' or model_type == 'random_forest' or model_type == 'lgbm'):\n",
    "        list_best_parameter = best_parameter(model_type, X_train, Y_train)\n",
    "        \n",
    "    # Predict and result all values\n",
    "    if (model_type != 'lgbm'):\n",
    "        accuracy, mean_error, mean_cv_score, var_cv_score = model_computing(X,\n",
    "                                                                        y,\n",
    "                                                                        model_type,\n",
    "                                                                        label_predict,\n",
    "                                                                        list_best_parameter,                                                                        \n",
    "                                                                        X_train,\n",
    "                                                                        Y_train,\n",
    "                                                                        X_test,\n",
    "                                                                        Y_test)\n",
    "    else:\n",
    "        accuracy, mean_error, mean_cv_score, var_cv_score = model_computing_non_binarize(X, y, categ, label_predict, X_train,\n",
    "                             Y_train, X_test, Y_test)\n",
    "\n",
    "    liste_result = [round(accuracy, 4), round(mean_error, 4),\n",
    "                    round(mean_cv_score, 4), round(var_cv_score, 4)]\n",
    "\n",
    "    return liste_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:09:08.955585Z",
     "start_time": "2020-01-17T18:09:08.935587Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculate for all model, all values. We decide the best model thanks all result\n",
    "\n",
    "def all_model(df : pd.core.frame.DataFrame, liste_label : list, liste_model : list, tab_score : pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    types = ['_A','_E','_CV','_VAR']\n",
    "    \n",
    "    for label in liste_label:\n",
    "        for model in liste_model:\n",
    "            #Calcul all model\n",
    "            score = modele(df, label, model, 86, 100)\n",
    "            for typ in types:\n",
    "                tab_score.loc[label, model + typ] = score[types.index(typ)]\n",
    "    return tab_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:09:09.464262Z",
     "start_time": "2020-01-17T18:09:09.436229Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data_non_binarized(data: pd.core.frame.DataFrame,\n",
    "                               to_predict: str) -> tuple:\n",
    "\n",
    "    # Getting list of object type columns\n",
    "    categ = data.select_dtypes('object').columns.tolist()\n",
    "\n",
    "    # Mapping those columns as string\n",
    "    data[categ] = data[categ].astype(str)\n",
    "\n",
    "    # Encoding those columns as integer categories\n",
    "    data[categ] = data[categ].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "    # Encoding those columns as integer categories\n",
    "    data = data[data[to_predict].notnull()]\n",
    "    X, y = data.drop([to_predict], axis=1), data[to_predict]\n",
    "\n",
    "    return(X, y, categ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:09:10.105115Z",
     "start_time": "2020-01-17T18:09:09.980952Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_computing_non_binarize(X: pd.core.frame.DataFrame,\n",
    "                                 y: pd.core.frame.DataFrame,\n",
    "                                 categ: list,\n",
    "                                 value_to_predict: str,\n",
    "                                 X_train: pd.core.frame.DataFrame,\n",
    "                                 Y_train: pd.core.frame.DataFrame,\n",
    "                                 X_test: pd.core.frame.DataFrame,\n",
    "                                 Y_test: pd.core.frame.DataFrame) -> tuple:\n",
    "\n",
    "    lgb_train = lgb.Dataset(X_train, Y_train, categorical_feature=categ)\n",
    "    lgb_eval = lgb.Dataset(X_test, Y_test, reference=lgb_train)\n",
    "\n",
    "    # parameters for lgbm\n",
    "    params = {\n",
    "        'num_leaves': 2500,\n",
    "        'max_depth': 17,\n",
    "        'min_data_in_leaf': 100,\n",
    "        'n_estimators': 200\n",
    "    }\n",
    "\n",
    "    # Training\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=80, \n",
    "\n",
    "                    valid_sets=lgb_eval)\n",
    "\n",
    "    prediction = gbm.predict(X_test)\n",
    "    # RMSE\n",
    "    #mean_error = rmse(prediction, Y_test)\n",
    "    mean_error = rmse(prediction, Y_test)\n",
    "\n",
    "    # Accuracy score\n",
    "    accuracy = accuracy_score(np.round(prediction), Y_test)\n",
    "\n",
    "    # Cross validation\n",
    "    cv_score = []\n",
    "    kf = KFold(n_splits=4, shuffle=True)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[list(train_index)], X.iloc[list(test_index)]\n",
    "        y_train, y_test = y.iloc[list(train_index)], y.iloc[list(test_index)]\n",
    "        lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=categ)\n",
    "        lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "        gbm = lgb.train(params,\n",
    "                        lgb_train,\n",
    "                        num_boost_round=80,\n",
    "                        valid_sets=lgb_eval)\n",
    "        prediction_cv = gbm.predict(X_test)\n",
    "        cv_score.append(accuracy_score(np.round(prediction_cv), y_test))\n",
    "\n",
    "    mean_cv_score = np.mean(cv_score)\n",
    "    var_cv_score = np.var(cv_score)\n",
    "\n",
    "    # Saving the model to disk\n",
    "    filename = 'g5_' + value_to_predict + '_lgbm.sav'\n",
    "    pickle.dump(gbm, open(filename, 'wb'))\n",
    "    print('File saved as ' + filename)\n",
    "\n",
    "    return(accuracy, mean_error, mean_cv_score, var_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:09:11.607020Z",
     "start_time": "2020-01-17T18:09:11.562964Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plots a bar chart of a metric score by label and model\n",
    "\n",
    "\n",
    "def plot_bars_model(labels_color: list, lists_models: list, labels_bar: list, measure: str):\n",
    "    \"\"\"\n",
    "    Documentation\n",
    "\n",
    "        Parameters:\n",
    "            labels_color: list of the labels wanted on legend\n",
    "            lists_models: list of the values wanted, grouped by model\n",
    "            labels_bar: list of the labels that are going to be on abscissa\n",
    "            measure: name of the measure on ordinate\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    width = 0.20\n",
    "    r1 = np.arange(len(lists_models[0]))\n",
    "    r2 = [x + width for x in r1]\n",
    "    r3 = [x + width for x in r2]\n",
    "    r4 = [x + width for x in r3]\n",
    "    rects1 = ax.bar(r1, lists_models[0], width, label=labels_color[0])\n",
    "    rects2 = ax.bar(r2, lists_models[1], width, label=labels_color[1])\n",
    "    rects3 = ax.bar(r3, lists_models[2], width, label=labels_color[2])\n",
    "    if len(lists_models) > 3:\n",
    "        rects4 = ax.bar(r4, lists_models[3], width, label=labels_color[3])\n",
    "    ax.set_ylabel(measure)\n",
    "    ax.set_title(measure + ' by label and model')\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.xticks([r + width for r in range(len(lists_models[0]))], labels_bar)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:09:12.139826Z",
     "start_time": "2020-01-17T18:09:12.127809Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Computes Root Mean Squarred Error between target and prediction\n",
    "\n",
    "\n",
    "def rmse(predictions: list, targets: list) -> float:\n",
    "    return np.sqrt(mean_squared_error(predictions, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T18:09:12.860880Z",
     "start_time": "2020-01-17T18:09:12.724698Z"
    }
   },
   "outputs": [],
   "source": [
    "# Computes a given model on given data, predicts and computes RMSE, accuracy score, cross validation, then saves the model.\n",
    "\n",
    "\n",
    "def model_computing(X: pd.core.frame.DataFrame,\n",
    "                    y: pd.core.frame.DataFrame,\n",
    "                    model_type: str,\n",
    "                    value_to_predict: str,\n",
    "                    list_param: list,\n",
    "                    X_train: pd.core.frame.DataFrame,\n",
    "                    Y_train: pd.core.frame.DataFrame,\n",
    "                    X_test: pd.core.frame.DataFrame,\n",
    "                    Y_test: pd.core.frame.DataFrame) -> tuple:\n",
    "    \"\"\"\n",
    "    Documentation\n",
    "\n",
    "        Parameters:\n",
    "            X: Preprocessed DataFrame containing features\n",
    "            y: Preprocessed DataFrame containing label\n",
    "            model_type: To choose between 'knn', 'logistic_regression', 'random_forest'\n",
    "            value_to_predict: Label name,\n",
    "            list_param: List of parameters, length and type of content depends on model_type\n",
    "            X_train: Splited preprocessed DataFrame containing features\n",
    "            Y_train: Splited preprocessed DataFrame containing labels\n",
    "            X_test: Splited preprocessed DataFrame containing features\n",
    "            Y_test: Splited preprocessed DataFrame containing labels\n",
    "\n",
    "        Out:\n",
    "            Tuple containing : \n",
    "                accuracy : Accuracy score on Splited DataFrames\n",
    "                mean_error : RMSE score on Splited DataFrames\n",
    "                mean_cv_score : Mean of accuracy scores computed by cross validation\n",
    "                var_cv_score : Variance of accuracy scores computed by cross validation\n",
    "\n",
    "    \"\"\"\n",
    "    if model_type == 'knn':\n",
    "        model = KNeighborsClassifier(n_neighbors=list_param[0])\n",
    "\n",
    "    elif model_type == 'logistic_regression':\n",
    "        model = LogisticRegression()\n",
    "\n",
    "    elif model_type == 'random_forest':\n",
    "        model = RandomForestRegressor(\n",
    "            max_depth=list_param[0], random_state=list_param[1], n_estimators=list_param[2])\n",
    "\n",
    "    # Training model and predicting\n",
    "    model.fit(X_train, Y_train)\n",
    "    prediction = model.predict(X_test)\n",
    "\n",
    "    # RMSE\n",
    "    mean_error = rmse(prediction, Y_test)\n",
    "\n",
    "    # Creation of a DataFrame with predictions\n",
    "    prediction = pd.DataFrame(prediction, columns=[\"Label\"])\n",
    "    prediction[\"index\"] = X_test.index\n",
    "\n",
    "    # Accuracy score\n",
    "    accuracy = accuracy_score(np.round(prediction[\"Label\"]), Y_test)\n",
    "\n",
    "    # Cross validation\n",
    "    cv_score = []\n",
    "    kf = KFold(n_splits=3)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[list(train_index)], X.iloc[list(test_index)]\n",
    "        y_train, y_test = y.iloc[list(train_index)], y.iloc[list(test_index)]\n",
    "        model.fit(X_train, y_train)\n",
    "        prediction_cv = model.predict(X_test)\n",
    "        cv_score.append(accuracy_score(np.round(prediction_cv), y_test))\n",
    "\n",
    "    mean_cv_score = np.mean(cv_score)\n",
    "    var_cv_score = np.var(cv_score)\n",
    "\n",
    "    # Saving the model to disk\n",
    "    filename = 'g5_' + value_to_predict + '_' + model_type + '.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    print('File saved as ' + filename)\n",
    "\n",
    "    return(accuracy, mean_error, mean_cv_score, var_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "264px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
